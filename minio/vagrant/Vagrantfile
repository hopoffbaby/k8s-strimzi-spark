# -*- mode: ruby -*-
# vi: set ft=ruby :

# Can be provisioned faster by calling "$env:VAGRANT_EXPERIMENTAL="disks"; vagrant up node<x> form multiple terminals to make parallel"

Vagrant.configure("2") do |config|
  config.vm.box = "ubuntu/jammy64"
  
  #config.vm.network "public_network"
  config.vm.synced_folder "../data", "/vagrant_data"
  config.vm.box_download_insecure = true

  config.vm.provision "generate_ssh_key", type: "shell", inline: <<-SHELL
    if [ ! -f /vagrant_data/id_rsa ]; then
      ssh-keygen -t rsa -b 4096 -f /vagrant_data/id_rsa -q -N ""
    fi
  SHELL

  (1..2).each do |i|
    config.vm.define "vm#{i}" do |node|
      node.vm.network "private_network", ip: "10.10.10.1#{i}"
      node.vm.network "public_network", bridge: "PANGP Virtual Ethernet Adapter Secure"
      node.vm.hostname = "vm#{i}"

      # Export VAGRANT_EXPERIMENTAL="disks"
      node.vm.disk :disk, name: "disk-1", size: "10GB"
      node.vm.disk :disk, name: "disk-2", size: "10GB"
      node.vm.disk :disk, name: "disk-3", size: "10GB"
      node.vm.disk :disk, name: "disk-4", size: "10GB"

      node.vm.provider "virtualbox" do |vb|
        vb.gui = false
        vb.memory = "3000"
        vb.cpus = 4
      end

      node.vm.provision "prereq", type: "shell", inline: <<-SHELL
        apt-get update
        apt-get install -y iputils-ping sshpass
        yes vagrant | passwd root
        echo "10.10.10.11 vm1 vm1" >> /etc/hosts
        echo "10.10.10.12 vm2 vm2" >> /etc/hosts
        sudo sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_config
        sudo sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config
        sudo systemctl restart sshd
      SHELL

      node.vm.provision "setup_ssh_keys", type: "shell", inline: <<-SHELL
        # Copy the generated SSH key to the VM for both vagrant and root users
        mkdir -p /home/vagrant/.ssh
        cp /vagrant_data/id_rsa /home/vagrant/.ssh/id_rsa
        cp /vagrant_data/id_rsa.pub /home/vagrant/.ssh/id_rsa.pub
        cat /vagrant_data/id_rsa.pub >> /home/vagrant/.ssh/authorized_keys
        chown -R vagrant:vagrant /home/vagrant/.ssh
        chmod 600 /home/vagrant/.ssh/id_rsa /home/vagrant/.ssh/id_rsa.pub /home/vagrant/.ssh/authorized_keys

        mkdir -p /root/.ssh
        cp /vagrant_data/id_rsa /root/.ssh/id_rsa
        cp /vagrant_data/id_rsa.pub /root/.ssh/id_rsa.pub
        cat /vagrant_data/id_rsa.pub >> /root/.ssh/authorized_keys
        chmod 600 /root/.ssh/id_rsa /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
      SHELL

      # node.vm.provision "install_k3s", type: "shell", inline: <<-SHELL
      #   # Install k3s and kubectl on vm1 (master)
      #   if [ "$(hostname)" == "vm1" ]; then
      #     curl -sfL https://get.k3s.io | sh -
      #     sudo cp /etc/rancher/k3s/k3s.yaml /home/vagrant/.kube/config
      #     sudo chown vagrant:vagrant /home/vagrant/.kube/config
      #   fi

      #   # Install k3s and kubectl on vm2 (node) and join to the cluster
      #   if [ "$(hostname)" == "vm2" ]; then
      #     until ping -c 1 10.10.10.11; do
      #       echo "Waiting for vm1 to start..."
      #       sleep 2
      #     done
      #     export K3S_TOKEN=$(ssh -o StrictHostKeyChecking=no -i /home/vagrant/.ssh/id_rsa root@10.10.10.11 cat /var/lib/rancher/k3s/server/node-token)
      #     curl -sfL https://get.k3s.io | K3S_URL=https://10.10.10.11:6443 K3S_TOKEN=$K3S_TOKEN sh -
      #     sudo mkdir -p /home/vagrant/.kube
      #     ssh -o StrictHostKeyChecking=no -i /home/vagrant/.ssh/id_rsa root@10.10.10.11:/etc/rancher/k3s/k3s.yaml /home/vagrant/.kube/config
      #     sudo sed -i 's/127.0.0.1/10.10.10.11/' /home/vagrant/.kube/config
      #     sudo chown vagrant:vagrant /home/vagrant/.kube/config
      #   fi
      # SHELL
    end
  end
end
